# -*- coding: utf-8 -*-
import os
import shutil
import csv
import hashlib
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

def get_file_md5(file_path):
    hash_md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except:
        return None

def run_universal_cleanup():
    print("=== macOS è¬ç”¨é‡è¤‡æª”æ¡ˆæ¸…ç†å·¥å…· ===")
    
    # 1. è¨­å®šæƒæåƒæ•¸
    scan_root = input("ğŸ‘‰ è«‹è¼¸å…¥è¦æ¸…ç†çš„è³‡æ–™å¤¾è·¯å¾‘: ").strip().replace("\\", "")
    if not os.path.exists(scan_root):
        print("âŒ è·¯å¾‘ä¸å­˜åœ¨ã€‚")
        return

    ext_input = input("ğŸ‘‰ è«‹è¼¸å…¥è¦æ¸…ç†çš„å‰¯æª”å (ä¾‹å¦‚ pdf,jpg,pngï¼Œç•™ç©ºå‰‡æƒææ‰€æœ‰æª”æ¡ˆ): ").lower()
    target_exts = set([f".{e.strip()}" for e in ext_input.split(',') if e.strip()]) if ext_input else None

    # 2. è¨­å®šå›æ”¶å€ (æ¡Œé¢)
    cleanup_folder = Path.home() / "Desktop" / f"Cleanup_Archive_{datetime.now().strftime('%Y%m%d_%H%M')}"
    cleanup_folder.mkdir(parents=True, exist_ok=True)
    log_file = cleanup_folder / "cleanup_report.csv"

    # 3. æª¢ç´¢æª”æ¡ˆ
    print("ğŸ” æ­£åœ¨æª¢ç´¢æª”æ¡ˆ...")
    all_files = []
    for p in Path(scan_root).rglob('*'):
        if p.is_file() and not p.name.startswith('._'):
            if target_exts is None or p.suffix.lower() in target_exts:
                all_files.append(p)
    
    seen_hashes = {}
    actions = []
    saved_size = 0

    # 4. æ¯”å°èˆ‡åˆ†æ
    for f_path in tqdm(all_files, desc="åˆ†æå…§å®¹ä¸­"):
        f_hash = get_file_md5(f_path)
        if not f_hash: continue

        if f_hash in seen_hashes:
            f_size = f_path.stat().st_size
            saved_size += f_size
            actions.append({
                'file': f_path,
                'reason': f"å…§å®¹èˆ‡ {seen_hashes[f_hash]} é‡è¤‡",
                'dest': cleanup_folder / f_path.name,
                'size_mb': round(f_size / (1024 * 1024), 2)
            })
        else:
            seen_hashes[f_hash] = str(f_path)

    # 5. åŸ·è¡Œæ¬ç§»
    if not actions:
        print("âœ¨ æ²’ç™¼ç¾é‡è¤‡æª”æ¡ˆï¼")
        return

    print(f"ğŸš€ ç™¼ç¾ {len(actions)} å€‹é‡è¤‡æª”æ¡ˆï¼Œé è¨ˆæ¸…å‡º {round(saved_size / (1024*1024), 2)} MB")
    
    with open(log_file, 'w', encoding='utf-8-sig', newline='') as csvf:
        writer = csv.DictWriter(csvf, fieldnames=['æª”æ¡ˆåç¨±', 'åŸå§‹è·¯å¾‘', 'åŸå› ', 'å¤§å°(MB)'])
        writer.writeheader()
        
        for act in actions:
            try:
                final_dest = act['dest']
                if final_dest.exists():
                    final_dest = cleanup_folder / f"{datetime.now().microsecond}_{act['file'].name}"
                
                shutil.move(str(act['file']), str(final_dest))
                writer.writerow({
                    'æª”æ¡ˆåç¨±': act['file'].name,
                    'åŸå§‹è·¯å¾‘': act['file'],
                    'åŸå› ': act['reason'],
                    'å¤§å°(MB)': act['size_mb']
                })
            except Exception as e:
                print(f"å¤±æ•—: {act['file'].name} - {e}")

    print("-" * 50)
    print(f"âœ… æ¸…ç†å®Œæˆï¼å·²ç§»è‡³æ¡Œé¢ {cleanup_folder.name}")
    print(f"ğŸ’¾ é‡‹æ”¾ç©ºé–“ï¼š{round(saved_size / (1024*1024), 2)} MB")

if __name__ == "__main__":
    run_universal_cleanup()