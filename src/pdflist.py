# -*- coding: utf-8 -*-
"""PDFLIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kUwNP9yze4bpRPdfb2QycBCebWwMF54p
"""

# @title ğŸ›¡ï¸ PDF æ™ºæ…§è‡ªå‹•åŒ–ç´¢å¼•ç³»çµ± (Enhanced Version)
# @markdown æœ¬å·¥å…·æœƒè‡ªå‹•æƒææŒ‡å®šç›®éŒ„ï¼Œæå– PDF æ‘˜è¦ä¸¦ç”Ÿæˆ CSV/HTML å ±å‘Šã€‚

import os
import json
import pandas as pd
from pathlib import Path
from google.colab import drive
from tqdm.notebook import tqdm
import datetime

# 1. ç’°å¢ƒé©é…èˆ‡ä¾è³´å®‰è£
try:
    import fitz  # PyMuPDF
except ImportError:
    print("ğŸ“¦ æ­£åœ¨å®‰è£å¿…è¦å…ƒä»¶ (PyMuPDF)...")
    !pip install -q pymupdf
    import fitz

# --- Colab Forms åƒæ•¸è¨­å®šå€å¡Š ---
# @markdown ### ğŸ“‚ è·¯å¾‘èˆ‡å®‰å…¨è¨­å®š
source_root = "/content/drive/MyDrive" # @param {type:"string"}
export_folder = "/content/drive/MyDrive/PDF_Index_Project" # @param {type:"string"}
output_name = "pdf_master_index.csv" # @param {type:"string"}

# @markdown ### âš™ï¸ åŸ·è¡Œæ§åˆ¶
dry_run = False # @param {type:"boolean"}
# @markdown > **Dry Run æ¨¡å¼**ï¼šé–‹å•Ÿæ™‚åƒ…æœƒåˆ—å‡ºæª”æ¡ˆè€Œä¸é€²è¡Œ PDF è§£æèˆ‡æª”æ¡ˆå¯«å…¥ã€‚
auto_checkpoint = 20 # @param {type:"slider", min:10, max:100, step:10}

class ColabAutomation:
    def __init__(self, source_root, export_folder, output_name):
        self.source = Path(source_root)
        self.export = Path(export_folder)
        self.output_csv = self.export / output_name
        self.checkpoint = self.export / "indexing_progress.json"
        self.html_report = self.export / "dashboard.html"
        self.results = []
        self.processed_paths = set()

    def initialize_env(self):
        """æ›è¼‰ Drive ä¸¦ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨"""
        if not Path('/content/drive').exists():
            drive.mount('/content/drive')
        self.export.mkdir(parents=True, exist_ok=True)
        print(f"âœ… ç’°å¢ƒåˆå§‹åŒ–å®Œæˆã€‚è¼¸å‡ºè·¯å¾‘ï¼š{self.export}")

    def load_checkpoint(self):
        """è¼‰å…¥æŒä¹…åŒ–é€²åº¦é˜²æ­¢é‡è¤‡åŸ·è¡Œ"""
        if self.checkpoint.exists():
            try:
                with open(self.checkpoint, 'r', encoding='utf-8') as f:
                    self.results = json.load(f)
                    self.processed_paths = {item['path'] for item in self.results}
                print(f"ğŸ”„ åµæ¸¬åˆ°é›²ç«¯é€²åº¦ï¼šå·²è·³é {len(self.processed_paths)} å€‹æª”æ¡ˆã€‚")
            except Exception as e:
                print(f"âš ï¸ é€²åº¦æª”æå£ï¼Œå°‡å¾é ­é–‹å§‹ã€‚")

    def preview(self):
        """å¯¦ä½œ Dry Run é‚è¼¯"""
        print("ğŸ” [Dry Run] æ­£åœ¨æƒæé è¨ˆè™•ç†çš„æª”æ¡ˆ...")
        files = list(self.source.rglob("*.pdf"))
        print(f"ğŸ“‹ é è¨ˆå°‡è™•ç† {len(files)} å€‹ PDF æª”æ¡ˆã€‚")
        for i, f in enumerate(files[:5]):
            print(f"   - {f.name}")
        if len(files) > 5: print(f"   ...ä»¥åŠå…¶ä»– {len(files)-5} å€‹æª”æ¡ˆ")
        print("\nğŸ’¡ è‹¥ç¢ºèªç„¡èª¤ï¼Œè«‹é—œé–‰ dry_run åƒæ•¸å¾Œé‡æ–°åŸ·è¡Œã€‚")

    def execute(self):
        """æ­£å¼åŸ·è¡Œ PDF å…§å®¹æå–é‚è¼¯"""
        self.load_checkpoint()

        # å–å¾—å¾…è™•ç†æ¸…å–®
        all_pdfs = [p for p in self.source.rglob("*.pdf") if str(p) not in self.processed_paths]

        if not all_pdfs:
            print("âœ… æ‰€æœ‰ PDF å·²åœ¨ç´¢å¼•ä¸­ï¼Œç„¡éœ€æ›´æ–°ã€‚")
            return

        pbar = tqdm(all_pdfs, desc="ğŸš€ æ­£åœ¨æ·±åº¦åˆ†æ PDF", unit="file")

        for i, path in enumerate(pbar):
            pbar.set_postfix_str(f"è™•ç†ä¸­: {path.name[:15]}")

            info = {
                "filename": path.name,
                "status": "Ready",
                "summary": "",
                "pages": 0,
                "folder": str(path.parent).replace('/content/drive/MyDrive', 'MyDrive'),
                "path": str(path),
                "file_size_bytes": 0, # æ–°å¢æ¬„ä½ï¼šæª”æ¡ˆå¤§å° (ä½å…ƒçµ„)
                "file_size_mb": 0.0, # æ–°å¢æ¬„ä½ï¼šæª”æ¡ˆå¤§å° (MB)
                "file_created_date": "", # æ–°å¢æ¬„ä½ï¼šæª”æ¡ˆå‰µå»ºæ—¥æœŸ
                "file_modified_date": "" # æ–°å¢æ¬„ä½ï¼šæª”æ¡ˆä¿®æ”¹æ—¥æœŸ
            }

            try:
                # å–å¾—æª”æ¡ˆå¤§å°
                file_size_bytes = os.path.getsize(path)
                info["file_size_bytes"] = file_size_bytes
                info["file_size_mb"] = round(file_size_bytes / (1024 * 1024), 2) # è½‰æ›ç‚º MB ä¸¦ä¿ç•™å…©ä½å°æ•¸

                # å–å¾—æª”æ¡ˆå‰µå»ºå’Œä¿®æ”¹æ—¥æœŸ
                creation_timestamp = os.path.getctime(path)
                modification_timestamp = os.path.getmtime(path)
                info["file_created_date"] = datetime.datetime.fromtimestamp(creation_timestamp).strftime('%Y-%m-%d %H:%M:%S')
                info["file_modified_date"] = datetime.datetime.fromtimestamp(modification_timestamp).strftime('%Y-%m-%d %H:%M:%S')

                with fitz.open(path) as doc:
                    info["status"] = "âœ… æ­£å¸¸" if not doc.is_encrypted else "ğŸ”’ åŠ å¯†"
                    info["pages"] = len(doc)
                    if not doc.is_encrypted and len(doc) > 0:
                        text = doc[0].get_text().strip()
                        info["summary"] = " ".join(text.split())[:200]
            except Exception as e:
                info["status"] = f"âŒ éŒ¯èª¤: {type(e).__name__}"

            self.results.append(info)

            # æ¯éš”æŒ‡å®šæ¬¡æ•¸å„²å­˜é€²åº¦ï¼Œé˜²ç¯„ IO ç•°å¸¸
            if (i + 1) % auto_checkpoint == 0:
                self._save_checkpoint()

        self._save_final_reports()

    def _save_checkpoint(self):
        with open(self.checkpoint, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

    def _save_final_reports(self):
        df = pd.DataFrame(self.results)
        # åŒ¯å‡º CSV (Excel å‹å–„ç·¨ç¢¼)
        df.to_csv(self.output_csv, index=False, encoding="utf-8-sig")

        # ç”Ÿæˆ HTML Dashboard
        html_style = "<style>body{font-family:sans-serif;padding:20px}table{width:100%;border-collapse:collapse}th,td{border:1px solid #ddd;padding:8px;text-align:left}th{background:#3498db;color:white}tr:nth-child(even){background:#f2f2f2}</style>"
        with open(self.html_report, "w", encoding="utf-8") as f:
            f.write(f"<h2>PDF ç´¢å¼•å ±å‘Š</h2>{html_style}")
            f.write(df.to_html(index=False))

        self._save_checkpoint() # æœ€å¾Œå­˜ä¸€æ¬¡ç¢ºä¿å®Œæ•´
        print(f"\nâœ¨ ä»»å‹™å®Œæˆï¼å ±å‘Šå„²å­˜æ–¼: {self.export}")

# --- å•Ÿå‹•é‚è¼¯ ---
bot = ColabAutomation(source_root, export_folder, output_name)
bot.initialize_env()

if dry_run:
    bot.preview()
else:
    bot.execute()

# @title AI prompt cell

import ipywidgets as widgets
from IPython.display import display, HTML, Markdown,clear_output
from google.colab import ai

dropdown = widgets.Dropdown(
    options=[],
    layout={'width': 'auto'}
)

def update_model_list(new_options):
    dropdown.options = new_options
update_model_list(ai.list_models())

text_input = widgets.Textarea(
    placeholder='Ask me anything....',
    layout={'width': 'auto', 'height': '100px'},
)

button = widgets.Button(
    description='Submit Text',
    disabled=False,
    tooltip='Click to submit the text',
    icon='check'
)

output_area = widgets.Output(
     layout={'width': 'auto', 'max_height': '300px','overflow_y': 'scroll'}
)

def on_button_clicked(b):
    with output_area:
        output_area.clear_output(wait=False)
        accumulated_content = ""
        for new_chunk in ai.generate_text(prompt=text_input.value, model_name=dropdown.value, stream=True):
            if new_chunk is None:
                continue
            accumulated_content += new_chunk
            clear_output(wait=True)
            display(Markdown(accumulated_content))

button.on_click(on_button_clicked)
vbox = widgets.GridBox([dropdown, text_input, button, output_area])

display(HTML("""
<style>
.widget-dropdown select {
    font-size: 18px;
    font-family: "Arial", sans-serif;
}
.widget-textarea textarea {
    font-size: 18px;
    font-family: "Arial", sans-serif;
}
</style>
"""))
display(vbox)



# ğŸ“¦ å®‰è£ Google Sheets API ç›¸é—œå‡½å¼åº«
# gspread ç”¨æ–¼èˆ‡ Google Sheets API äº’å‹•
# gspread-dataframe ç”¨æ–¼æ–¹ä¾¿åœ°å°‡ Pandas DataFrame å¯«å…¥ Google Sheets
!pip install -q gspread gspread-dataframe

"""### âš™ï¸ Google Sheets èº«ä»½é©—è­‰

ç‚ºäº†è®“ Colab èƒ½å¤ å­˜å–æ‚¨çš„ Google Sheetsï¼Œæ‚¨éœ€è¦é€²è¡Œèº«ä»½é©—è­‰ã€‚åŸ·è¡Œä¸‹é¢çš„ç¨‹å¼ç¢¼å¾Œï¼Œæœƒå½ˆå‡ºä¸€å€‹é©—è­‰è¦–çª—ï¼Œè«‹ä¾ç…§æŒ‡ç¤ºå®Œæˆæˆæ¬Šã€‚**å¦‚æœæ‚¨å·²ç¶“æ›è¼‰äº† Google Driveï¼Œé€šå¸¸é€™ä¸€æ­¥æœƒè‡ªå‹•ä½¿ç”¨ç¾æœ‰çš„èªè­‰ã€‚**
"""

import gspread
from google.colab import auth
import pandas as pd
import google.auth # åŒ¯å…¥ google.auth ä»¥å–å¾—èªè­‰æ†‘è­‰

# åŸ·è¡Œ Google èº«ä»½é©—è­‰
auth.authenticate_user()

# ä¿®æ­£: å¾ authenticate_user() å–å¾—çš„æ†‘è­‰ï¼Œç›´æ¥ç”¨æ–¼ gspread.Client
credentials, project = google.auth.default()
gc = gspread.Client(auth=credentials)

print("âœ… Google Sheets èº«ä»½é©—è­‰æˆåŠŸï¼")

# å¾ Drive è¼‰å…¥ä¹‹å‰ç”Ÿæˆçš„ CSV æª”æ¡ˆ
# è«‹ç¢ºä¿ `export_folder` å’Œ `output_name` èˆ‡ä¸Šä¸€å€‹å„²å­˜æ ¼çš„è¨­å®šä¸€è‡´
export_folder = "/content/drive/MyDrive/PDF_Index_Project" # @param {type:"string"}
output_name = "pdf_master_index.csv" # @param {type:"string"}
csv_file_path = f"{export_folder}/{output_name}"

try:
    df_to_export = pd.read_csv(csv_file_path, encoding='utf-8-sig')
    print(f"âœ… å·²æˆåŠŸå¾ '{csv_file_path}' è¼‰å…¥è³‡æ–™ã€‚")
except FileNotFoundError:
    print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ '{csv_file_path}'ã€‚è«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢ºï¼Œæˆ–å…ˆåŸ·è¡Œä¸Šæ–¹çš„ PDF ç´¢å¼•ç¨‹å¼ä»¥ç”Ÿæˆ CSV æª”æ¡ˆã€‚")
    exit()

# è¨­å®š Google Sheet åç¨±
gsheet_name = "PDF Master Index Report" # @param {type:"string"}

# å»ºç«‹æ–°çš„ Google Sheet æˆ–é–‹å•Ÿç¾æœ‰çš„ Sheet
try:
    sh = gc.open(gsheet_name)
    print(f"ğŸ”„ å·²é–‹å•Ÿç¾æœ‰ Google Sheet: '{gsheet_name}'")
except gspread.exceptions.SpreadsheetNotFound:
    sh = gc.create(gsheet_name)
    print(f"âœ¨ å·²å»ºç«‹æ–°çš„ Google Sheet: '{gsheet_name}'")

# å°‡è³‡æ–™å¯«å…¥ç¬¬ä¸€å€‹å·¥ä½œè¡¨ (worksheet)
wks = sh.get_worksheet(0) # ç²å–ç¬¬ä¸€å€‹å·¥ä½œè¡¨

# æ¸…é™¤ç¾æœ‰å…§å®¹ (å¯é¸ï¼Œé¿å…é‡è¤‡è³‡æ–™)
wks.clear()

# å°‡ DataFrame å¯«å…¥ Google Sheet
from gspread_dataframe import set_with_dataframe
set_with_dataframe(wks, df_to_export)

print(f"âœ… è³‡æ–™å·²æˆåŠŸå¯«å…¥ Google Sheet: '{gsheet_name}'")
print(f"ğŸ”— æ‚¨å¯ä»¥åœ¨é€™è£¡æŸ¥çœ‹ Google Sheet: {sh.url}")