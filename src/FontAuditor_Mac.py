# -*- coding: utf-8 -*-
"""
FontAuditor_Mac_V3.py
ä¿®æ­£ç‰ˆï¼šè§£æ±º fontTools ç‰ˆæœ¬ç›¸å®¹æ€§å•é¡Œ
"""

import os
import csv
import re
import hashlib
import gc
from pathlib import Path
from datetime import datetime

def install_requirements():
    try:
        from fontTools.ttLib import TTFont
        from tqdm import tqdm
    except ImportError:
        print("æ­£åœ¨å®‰è£æˆ–æ›´æ–°å¿…è¦å¥—ä»¶ (fonttools, tqdm)...")
        os.system('pip3 install --upgrade fonttools tqdm -q')

install_requirements()
from fontTools.ttLib import TTFont
from tqdm import tqdm

def get_file_md5(file_path):
    hash_md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except Exception:
        return "MD5_Error"

def get_clean_meta(name_table, name_id):
    # å˜—è©¦ä¸åŒç·¨ç¢¼ç´€éŒ„ (ID4: Full Name, ID1: Family Name)
    record = name_table.getName(name_id, 3, 1, 1033) or \
             name_table.getName(name_id, 1, 0, 0) or \
             name_table.getName(name_id, 3, 1, 1028)
    if not record: return "N/A"
    try:
        return re.sub(r'\s+', ' ', record.toUnicode()).strip()
    except:
        return "Encoding Error"

def run_audit():
    print("=== macOS å­—é«”æ·±åº¦ç›¤é»å·¥å…· V3 (ç›¸å®¹æ€§ä¿®æ­£ç‰ˆ) ===")
    
    default_scan = "/Library/Fonts"
    user_input = input(f"ğŸ‘‰ æƒæè·¯å¾‘ (é è¨­ {default_scan}): ").strip()
    scan_root = user_input if user_input else default_scan
    
    scan_path = Path(scan_root)
    if not scan_path.exists():
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°è·¯å¾‘ '{scan_root}'")
        return

    report_folder = Path.home() / "Desktop/Font_Audit_Reports"
    report_folder.mkdir(parents=True, exist_ok=True)
    csv_file = report_folder / f"Font_Inventory_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"

    fieldnames = ['ç‹€æ…‹ (Status)', 'MD5_Hash', 'å­—é«”å…¨å (ID4)', 'å­—é«”å®¶æ— (ID1)', 'ç‰ˆæœ¬ (ID5)', 'æª”æ¡ˆå¤§å°(MB)', 'åŸå§‹è·¯å¾‘', 'è¡çªä¾†æº']
    font_exts = {'.ttf', '.otf', '.ttc', '.dfont'}
    
    print("ğŸ” æ­£åœ¨æª¢ç´¢æª”æ¡ˆçµæ§‹...")
    file_list = []
    for p in scan_path.rglob('*'):
        try:
            if p.is_file() and p.suffix.lower() in font_exts and not p.name.startswith('._'):
                file_list.append(p)
        except:
            continue

    total_files = len(file_list)
    if total_files == 0:
        print("ğŸ“­ æ‰¾ä¸åˆ°å­—é«”æª”æ¡ˆã€‚")
        return

    seen_hashes = {}
    duplicate_count = 0
    error_count = 0

    with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()

        with tqdm(total=total_files, desc="ç›¤é»é€²åº¦", unit="file", colour='green') as pbar:
            for file_path in file_list:
                font = None
                try:
                    # ç¬¬ä¸€éšæ®µï¼šè¨ˆç®— MD5 (é€™éƒ¨åˆ†ä½ ä¹‹å‰çš„çµæœé¡¯ç¤ºæ˜¯æˆåŠŸçš„)
                    file_hash = get_file_md5(file_path)
                    
                    status = "Unique"
                    conflict_source = ""
                    if file_hash in seen_hashes:
                        status = "Duplicate"
                        conflict_source = seen_hashes[file_hash]
                        duplicate_count += 1
                    else:
                        seen_hashes[file_hash] = str(file_path)

                    # ç¬¬äºŒéšæ®µï¼šè®€å– Metadata (å·²ç§»é™¤ç›¸å®¹æ€§å•é¡Œåƒæ•¸)
                    # åªä¿ç•™æœ€åŸºæœ¬çš„åƒæ•¸ä»¥ç¢ºä¿èˆŠç‰ˆ fontTools ä¹Ÿèƒ½è·‘
                    font = TTFont(str(file_path), fontNumber=0, lazy=True)
                    names = font['name']

                    writer.writerow({
                        'ç‹€æ…‹ (Status)': status,
                        'MD5_Hash': file_hash,
                        'å­—é«”å…¨å (ID4)': get_clean_meta(names, 4),
                        'å­—é«”å®¶æ— (ID1)': get_clean_meta(names, 1),
                        'ç‰ˆæœ¬ (ID5)': get_clean_meta(names, 5),
                        'æª”æ¡ˆå¤§å°(MB)': round(file_path.stat().st_size / (1024 * 1024), 2),
                        'åŸå§‹è·¯å¾‘': str(file_path),
                        'è¡çªä¾†æº': conflict_source
                    })
                except Exception as e:
                    error_count += 1
                    writer.writerow({
                        'ç‹€æ…‹ (Status)': 'Read_Error',
                        'MD5_Hash': file_hash if 'file_hash' in locals() else 'N/A',
                        'å­—é«”å…¨å (ID4)': f"è®€å–å¤±æ•—: {str(e)}",
                        'åŸå§‹è·¯å¾‘': str(file_path)
                    })
                finally:
                    if font: font.close()
                    pbar.update(1)
                    if pbar.n % 50 == 0:
                        f.flush()
                        gc.collect()

    print("-" * 50)
    print(f"âœ¨ ç›¤é»å®Œæˆï¼")
    print(f"ğŸ“Š ç¸½è™•ç†æ•¸: {total_files}")
    print(f"âš ï¸ é‡è¤‡æ•¸: {duplicate_count} | âŒ è®€å–å¤±æ•—æ•¸: {error_count}")
    print(f"ğŸ”— å ±å‘Šè·¯å¾‘ï¼š{csv_file}")

if __name__ == "__main__":
    run_audit()